!obj:pylearn2.train.Train {
    dataset: &train !obj:research.code.pylearn2.datasets.timit.TIMIT {
        which_set: 'train',
        frame_length: &fl 1,
        frames_per_example: &fpe 100
    },
    model: !obj:mlp_with_source.MLPWithSource {
        batch_size: 2048,
        layers: [
            !obj:pylearn2.models.mlp.RectifiedLinear {
                layer_name: 'h1',
                dim: 300,
                irange: 0.05
            },
            !obj:pylearn2.models.mlp.RectifiedLinear {
                layer_name: 'h2',
                dim: 200,
                irange: 0.05
            },
            !obj:pylearn2.models.mlp.Linear {
                layer_name: 'h3',
                dim: 1,
                irange: 0.05
            }
        ],
        input_space: !obj:pylearn2.space.CompositeSpace {
            components: [
                !obj:pylearn2.space.VectorSpace {
                    dim: *fpe
                },
                !obj:pylearn2.space.VectorSpace {
                    dim: 62
                }
            ]
        },
        input_source: ['features', 'phones']
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        learning_rate: 0.1,
        monitoring_dataset: {
            'train': *train,
            'valid': !obj:research.code.pylearn2.datasets.timit.TIMIT {
                which_set: 'valid',
                frame_length: *fl,
                frames_per_example: *fpe
            },
            'test': !obj:research.code.pylearn2.datasets.timit.TIMIT {
                which_set: 'test',
                frame_length: *fl,
                frames_per_example: *fpe
            }
        },
        cost: !obj:pylearn2.costs.cost.SumOfCosts {
            costs: [
                !obj:pylearn2.costs.mlp.Default {},
                !obj:pylearn2.costs.mlp.WeightDecay {
                    coeffs: [0.0, 0.0, 0.0]
                }
            ]
        
        },
        termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {
            channel_name: 'valid_objective',
            prop_decrease: 0.005,
            N: 10
        },
        train_iteration_mode: 'random_uniform',
        monitor_iteration_mode: 'random_uniform',
        batches_per_iter: 5000,
        monitoring_batches: 7500
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
            channel_name: 'valid_objective',
            save_path: '/data/lisa/exp/raymonjp/speech_synthesis/mlp_phones300-200_1.pkl'
        },
        !obj:pylearn2.training_algorithms.sgd.MonitorBasedLRAdjuster {
            dataset_name: 'valid'
        }
    ]
}
